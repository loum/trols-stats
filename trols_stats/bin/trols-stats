#!/usr/bin/python

import sys
import os
import argparse
# import json

import trols_stats.interface
# from filer.files import get_directory_files

CONF = os.path.join(os.sep, 'etc', 'trols-stats', 'conf', 'config.conf')
DESCRIPTION = """TROLS Stats Tool"""


def main():
    """Script entry point.

    """
    parser = argparse.ArgumentParser(description=DESCRIPTION)
    parser.add_argument('-c',
                        '--config-file',
                        action='store',
                        dest='config_file')

    # Prepare the argument list and config.
    args = parser.parse_args()

    config_file = args.config_file
    if args.config_file is None:
        if os.path.exists(CONF):
            config_file = CONF

    if config_file is None:
        sys.exit('Unable to source the default TROLS Stats config.conf')

    conf = trols_stats.Config(config_file)

    loader = trols_stats.interface.Loader()

    # Load the competitions.
    comps_html = loader.request(conf.main_results)

    comps_xpath = '//select[@id="section" and @name="section"]/option'
    comps_map = trols_stats.Scraper.scrape_competition_ids(comps_html,
                                                           comps_xpath)

    # Cycle through each competition and get the match codes.
    uri = 'http://trols.org.au/nejta/results.php'
    match_xpath = '//a[contains(@onclick, "open_match")]'
    for comp, code in comps_map.iteritems():
        query_args = {
            'which': 1,
            'style': '',
            'daytime': 'AA',
            'section': code,
        }
        matches_html = loader.request(uri, query_args)
        match_codes = trols_stats.Scraper.scrape_match_ids(matches_html,
                                                           match_xpath)

        match_uri = 'http://www.trols.org.au/nejta/match_popup.php'
        for match_code in match_codes:
            request_kwargs = {
                'uri': match_uri,
                'request_args': {
                    'matchid': match_code,
                },
                'cache_dir':  conf.cache_dir,
                'force_cache': False
            }
            match_html = loader.request(**request_kwargs)

#        for html_file in get_directory_files(conf.cache_dir):
#            loader.build_game_map(match_html)
#
#        tmp_games = []
#        for game in loader.games:
#            tmp_games.append(game())
#
#        with open('stats.json', 'w') as games_fh:
#            games_fh.write(json.dumps(tmp_games,
#                                      sort_keys=True,
#                                      indent=4,
#                                      separators=(',', ': ')))


if __name__ == '__main__':
    main()

#!/usr/bin/env python

import sys
import os
import argparse
import json
import urllib

import trols_stats.interface

CONF = os.path.join(os.sep, 'etc', 'trols-stats', 'conf', 'config.conf')
DESCRIPTION = """TROLS Stats Tool"""


def main():
    """Script entry point.

    """
    parser = argparse.ArgumentParser(description=DESCRIPTION)
    parser.add_argument('-c',
                        '--config-file',
                        action='store',
                        dest='config_file')
    # Add sub-command support.
    subparsers = parser.add_subparsers(help='commands')

    # 'source' subcommand.
    source_help = 'Pull data from TROLS endpoint'
    source_parser = subparsers.add_parser('source', help=source_help)
    source_parser.set_defaults(func=source)

    force_help = 'Overwrite cache'
    source_parser.add_argument('-F',
                               '--force',
                               action='store_true',
                               help=force_help,
                               dest='force')

    # 'scrape' subcommand.
    scrape_help = 'Build player game map'
    scrape_parser = subparsers.add_parser('scrape', help=scrape_help)
    scrape_parser.set_defaults(func=scrape)

    dump_help = 'Override file to write out JSON (default "stats.json")'
    scrape_parser.add_argument('-d',
                               '--dump',
                               action='store',
                               default='stats.json',
                               help=dump_help,
                               dest='dump')

    # Prepare the argument list and config.
    args = parser.parse_args()

    config_file = args.config_file
    if args.config_file is None:
        if os.path.exists(CONF):
            config_file = CONF

    if config_file is None:
        sys.exit('Unable to source the default TROLS Stats config.conf')

    conf = trols_stats.Config(config_file)

    args.func(args, conf)


def source(args, conf):
    loader = trols_stats.interface.Loader()

    # Load the competitions.
    #
    # TODO: Archived seasons have a "daytime" query parameter.
    results_url = 'http://trols.org.au/{}/results.php'
    for league, daytimes in conf.trols_urls.items():
        for daytime in daytimes.split(','):
            option_value = daytime
            if league.lower() == 'nejta':
                daytime = str()

            comps_html = loader.request(results_url.format(league),
                                        {'daytime': daytime})
            comp_name_xpath = (
                '//table/tr/td/select/'
                'option[@value="{}"]/text()'.format(option_value)
            )
            kwargs = {
                'html': comps_html,
                'xpath': comp_name_xpath,
                'tokenise': True,
                'league': league,
            }
            comp_name = trols_stats.Scraper.scrape_competition_name(**kwargs)

            # Restore the daytime.  It's a NEJTA thing :-/
            daytime = option_value

            # Each competition is made of sections.  For example, "BOYS 21".
            # Each section is identified by a code.
            comps_xpath = '//select[@id="section" and @name="section"]/option'
            comps_map = trols_stats.Scraper.scrape_competition_ids(comps_html,
                                                                comps_xpath)

            # Cycle through each competition and get the match codes.
            match_xpath = '//a[contains(@onclick, "open_match")]'
            for code in comps_map.values():
                query_args = {
                    'which': 1,
                    'style': '',
                    'daytime': option_value,
                    'section': code,
                }
                matches_html = loader.request(results_url.format(league),
                                            query_args)
                match_codes = trols_stats.Scraper.scrape_match_ids(matches_html,
                                                                match_xpath)

                root_uri = (
                    'http://www.trols.org.au/{}/match_popup.php'.format(league)
                )
                for match_code in match_codes:
                    request_args = {
                        'matchid': match_code,
                        'seasonid': str(),
                    }
                    match_uri = '{}?{}'.format(root_uri,
                                            urllib.parse.urlencode(request_args))
                    request_kwargs = {
                        'uri': match_uri,
                        'cache_dir':  conf.cache,
                        'force_cache': args.force,
                        'comp_token': comp_name,
                        'match_id': match_code
                    }
                    loader.request(**request_kwargs)


def scrape(args, conf):
    model = trols_stats.DataModel(shelve=conf.shelve)
    model.construct(conf.cache)

if __name__ == '__main__':
    main()
